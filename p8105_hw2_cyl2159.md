p8105_hw2_cyl2159
================
Chhiring Lama
2024-09-29

## *Problem 1*

Importing and cleaning the dataset:

``` r
nyc_transit_df <- read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", "")) 

nyc_transit_clean_df <- nyc_transit_df |> 
  janitor::clean_names() |> 
  select(line:entry, vending, ada, ada_notes) |> 
  mutate(
    entry = case_match(entry,
                       "YES" ~ TRUE,
                       "NO" ~ FALSE), 
    vending = case_match(vending, 
                         "YES" ~ TRUE, 
                         "NO" ~ FALSE)) |> 
  mutate_at(c(5:15), as.character) |> 
  pivot_longer(
    route1:route11, 
    names_to = "route_number",
    values_to = "subway_line", 
    names_prefix = "route"
  ) |> 
  drop_na(subway_line) 
```

The NYC transit dataset initially had 32 columns and 1868 rows. Because
we wanted a cleaner data, I recognized there the routes had empty cells,
so I replaced the values with `NA`, and introduced snake-case column
names. I used `case_match` within `mutate` to convert “YES” and “NO”
values to logical variables. Similarly, I cleaned the dataset further by
gathering the columns between `route1` and `route11` with `pivot_longer`
into two columns `route_number` and `subway_line`. This step introduced
columns with NA values for `subway_line` which are redundant rows, so I
dropped the rows with missing data for `subway_line`. The resulting
dataset has 11 columns containing the following variables:
`line, station_name, station_latitude, station_longitude, entrance_type, entry, vending, ada, ada_notes, route_number`
and `subway_line`. There are 4270 observations/rows. I believe that the
data are tidy after these data wrangling steps.

1)  How many distinct stations are there? Note that stations are
    identified both by name and by line (e.g. 125th St 8th Avenue; 125st
    Broadway; 125st Lenox); the distinct function may be useful here.

``` r
nyc_transit_clean_df <- nyc_transit_clean_df |> 
  mutate(station = paste(line, station_name, sep = ":")) 

number_of_stations <- nyc_transit_clean_df |> 
  select(station) |> 
  unique() |> 
  nrow()
```

- There are a total of 465 distinct stations in NYC.

2)  How many stations are ADA compliant?

``` r
ada_compliance <- nyc_transit_clean_df |> 
  select(station, ada) |> 
  filter(ada == TRUE) |> 
  unique() |> 
  nrow()
```

- 84 stations are ADA compliant.

3)  What proportion of station entrances / exits without vending allow
    entrance?  
    We can use the wide dataset here since there each row is a distinct
    entrance/exit whereas in the tidy dataset (`nyc_transit_clean_df`) a
    single entrance is represented in multiple rows and each row there
    represents a single subway line served by a particular entrance of a
    station.

``` r
vending_system <- nyc_transit_df |> 
  janitor::clean_names() |> 
  mutate(station = paste(line, station_name, sep = ":")) |> 
  filter(vending == "NO") |> 
  mutate(total_no_entrance = n()) |> 
  filter(entry == "YES") |>
  select(entry, total_no_entrance) |> 
  mutate(entry_prop = n()/total_no_entrance) |> 
  unique() 
  
entry_prop <- round(pull(vending_system, entry_prop), digits = 2)
```

- The proportion of station entrances/exits without vending that allow
  entrance is 0.38 as calculated by the column `entry_prop`.  

Reformat data so that route number and route name are distinct
variables. How many distinct stations serve the A train? Of the stations
that serve the A train, how many are ADA compliant?

The route numbers and route name are also distinct variables in the tidy
dataset `nyc_transit_clean_df` as columns `route_number` and
`subway_line`.

Subsetting the stations that serve A train:

``` r
a_train_stations <- nyc_transit_clean_df |> 
  mutate(station = paste(line, station_name, sep = ":")) |> 
  filter(subway_line == "A") |> 
  select(station, ada) |> 
  unique()

nrow_a_train_stations <- a_train_stations |> 
  nrow()

ada_complian_a_stations <- a_train_stations |> 
  filter(ada == TRUE) |> 
  nrow()
```

- There are 60 stations serving the A train. Out of them, 17 are ADA
  compliant.

## *Problem 2*

Importing the Mr. Trash Wheel dataset:

``` r
mr_trash_wheel_df <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                             sheet = "Mr. Trash Wheel", range = "A2:N586", 
                             na = c("NA", "", "")) |> 
  janitor::clean_names() |>
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)), 
         group = "mr_trash_wheel", 
         year = as.numeric(year))
```

Importing the Professor Trash Wheel dataset and omit rows with any
missing data for a dumpster:

``` r
prof_trash_wheel_df <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                             sheet = "Professor Trash Wheel", range = "A2:M108",
                             na = c("NA", "", "")) |> 
  janitor::clean_names() |> 
  mutate(group = "prof_trash_wheel")

total_trash_by_prof <- prof_trash_wheel_df |> 
  select(weight_tons) |> 
  sum()
```

Importing the Gwynnda dataset and omit rows with any missing data for a
dumpster:

``` r
gwynnda_trash_wheel_df <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                             sheet = "Gwynnda Trash Wheel", range = "A2:L157",
                             na = c("NA", "", "")) |> 
  janitor::clean_names() |> 
  mutate(group = "gwynnda_trash_wheel")
total_cigratte_by_gwynnda <- gwynnda_trash_wheel_df |> 
  filter(month == "June", year == "2022") |> 
  select(cigarette_butts) |> 
  sum() |> 
  as.integer()
```

Joining the datasets:

``` r
common_cols_between_mr_prof <- intersect(colnames(mr_trash_wheel_df), 
                                         colnames(prof_trash_wheel_df))
common_cols_between_mr_gwynnda <- intersect(colnames(mr_trash_wheel_df), 
                                     colnames(gwynnda_trash_wheel_df))

unique_cols_between_mr_prof <- setdiff(colnames(mr_trash_wheel_df), 
                                         colnames(prof_trash_wheel_df))
unique_cols_between_mr_gwynnda <- setdiff(colnames(mr_trash_wheel_df), 
                                     colnames(gwynnda_trash_wheel_df))

combined_trash_wheel_df <- mr_trash_wheel_df |> 
  full_join(prof_trash_wheel_df, by = common_cols_between_mr_prof) |> 
  full_join(gwynnda_trash_wheel_df, by = common_cols_between_mr_gwynnda)

unique_trash <- combined_trash_wheel_df |> 
  select(plastic_bottles:sports_balls) 

combined_trash_wheel_clean_df <- combined_trash_wheel_df |> 
  pivot_longer(
    plastic_bottles:sports_balls, 
    names_to = "waste_type", 
    values_to = "number_of_waste_collected"
  )
```

Among the three sheets that we used from the `Mr. Trash Wheel` workbook,
the dataset `Mr. Trash Wheel` had the most variables recorded (15),
while the datasets `Professor Trash Wheel` and `Gwynnda Trash Wheel` had
14 and 13 variables respectively. After combining the three datasets,
there are information about 845 dumpsters, and a total of 5915
observations after tidying the data. For each groups, there are data on
volume and weight of trash collected, number and types of each trash
collected. There are 7 types of trash and they are:
`plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls`.
We are missing data for `sports_balls` in observations from
`Professor Trash Wheel`, and `glass_bottles, sports_balls` from
`Gwynnda Trash Wheel`. For the available data, Professor Trash Wheel
collected 216.26 tons trash. Similarly, Gwynnda collected 18120
cigarette butts in June of 2022.
