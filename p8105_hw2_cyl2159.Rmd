---
title: "p8105_hw2_cyl2159"
author: "Chhiring Lama"
date: "2024-09-29"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(snakecase)
```

## *Problem 1*

Importing and cleaning the dataset:
```{r import_data, message = FALSE}
nyc_transit_df <- read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", "")) 

nyc_transit_clean_df <- nyc_transit_df |> 
  janitor::clean_names() |> 
  select(line:entry, vending, ada, ada_notes) |> 
  mutate(
    entry = case_match(entry,
                       "YES" ~ TRUE,
                       "NO" ~ FALSE), 
    vending = case_match(vending, 
                         "YES" ~ TRUE, 
                         "NO" ~ FALSE)) |> 
  mutate_at(c(5:15), as.character) |> 
  pivot_longer(
    route1:route11, 
    names_to = "route_number",
    values_to = "subway_line", 
    names_prefix = "route"
  ) |> 
  drop_na(subway_line) 
```

The NYC transit dataset initially had `r ncol(nyc_transit_df)` columns and `r nrow(nyc_transit_df)` rows. Because we wanted a cleaner data, I recognized there the routes had empty cells, so I replaced the values with `NA`, and introduced snake-case column names. I used `case_match` within `mutate` to convert "YES" and "NO" values to logical variables. Similarly, I cleaned the dataset further by gathering the columns between `route1` and `route11` with `pivot_longer` into two columns `route_number` and `subway_line`. This step introduced columns with NA values for `subway_line` which are redundant rows, so I dropped the rows with missing data for `subway_line`. The resulting dataset has `r ncol(nyc_transit_clean_df)` columns containing the following variables: ``r names(nyc_transit_clean_df)[1:10]`` and ``r names(nyc_transit_clean_df)[11]``. There are `r nrow(nyc_transit_clean_df)` observations/rows. I believe that the data are tidy after these data wrangling steps. 

1) How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here. 
```{r}
nyc_transit_clean_df <- nyc_transit_clean_df |> 
  mutate(station = paste(line, station_name, sep = ":")) 

number_of_stations <- nyc_transit_clean_df |> 
  select(station) |> 
  unique() |> 
  nrow()
```
- There are a total of `r number_of_stations` distinct stations in NYC. 

2) How many stations are ADA compliant? 
```{r}
ada_compliance <- nyc_transit_clean_df |> 
  select(station, ada) |> 
  filter(ada == TRUE) |> 
  unique() |> 
  nrow()
```
- `r ada_compliance` stations are ADA compliant. 

3) What proportion of station entrances / exits without vending allow entrance? \
We can use the wide dataset here since there each row is a distinct entrance/exit whereas in the tidy dataset (`nyc_transit_clean_df`) a single entrance is represented in multiple rows and each row there represents a single subway line served by a particular entrance of a station. 
```{r}
vending_system <- nyc_transit_df |> 
  janitor::clean_names() |> 
  mutate(station = paste(line, station_name, sep = ":")) |> 
  filter(vending == "NO") |> 
  mutate(total_no_entrance = n()) |> 
  filter(entry == "YES") |>
  select(entry, total_no_entrance) |> 
  mutate(entry_prop = n()/total_no_entrance) |> 
  unique() 
  
entry_prop <- round(pull(vending_system, entry_prop), digits = 2)
```
- The proportion of station entrances/exits without vending that allow entrance is `r entry_prop` as calculated by the column `entry_prop`. \

Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

The route numbers and route name are also distinct variables in the tidy dataset `nyc_transit_clean_df` as columns `route_number` and `subway_line`. 

Subsetting the stations that serve A train:
```{r}
a_train_stations <- nyc_transit_clean_df |> 
  mutate(station = paste(line, station_name, sep = ":")) |> 
  filter(subway_line == "A") |> 
  select(station, ada) |> 
  unique()

nrow_a_train_stations <- a_train_stations |> 
  nrow()

ada_complian_a_stations <- a_train_stations |> 
  filter(ada == TRUE) |> 
  nrow()
```

- There are `r nrow_a_train_stations` stations serving the A train. Out of them, `r ada_complian_a_stations` are ADA compliant. 

## *Problem 2*

Importing the Mr. Trash Wheel dataset:
```{r}
mr_trash_wheel_df <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                             sheet = "Mr. Trash Wheel", range = "A2:N586", 
                             na = c("NA", "", "")) |> 
  janitor::clean_names() |>
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)), 
         group = "mr_trash_wheel", 
         year = as.numeric(year))
```

Importing the Professor Trash Wheel dataset and omit rows with any missing data for a dumpster:
```{r}
prof_trash_wheel_df <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                             sheet = "Professor Trash Wheel", range = "A2:M108",
                             na = c("NA", "", "")) |> 
  janitor::clean_names() |> 
  mutate(group = "prof_trash_wheel")

total_trash_by_prof <- prof_trash_wheel_df |> 
  select(weight_tons) |> 
  sum()
```

Importing the Gwynnda dataset and omit rows with any missing data for a dumpster:
```{r}
gwynnda_trash_wheel_df <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                             sheet = "Gwynnda Trash Wheel", range = "A2:L157",
                             na = c("NA", "", "")) |> 
  janitor::clean_names() |> 
  mutate(group = "gwynnda_trash_wheel")
total_cigratte_by_gwynnda <- gwynnda_trash_wheel_df |> 
  filter(month == "June", year == "2022") |> 
  select(cigarette_butts) |> 
  sum() |> 
  as.integer()
```

Joining the datasets:
```{r}
common_cols_between_mr_prof <- intersect(colnames(mr_trash_wheel_df), 
                                         colnames(prof_trash_wheel_df))
common_cols_between_mr_gwynnda <- intersect(colnames(mr_trash_wheel_df), 
                                     colnames(gwynnda_trash_wheel_df))

unique_cols_between_mr_prof <- setdiff(colnames(mr_trash_wheel_df), 
                                         colnames(prof_trash_wheel_df))
unique_cols_between_mr_gwynnda <- setdiff(colnames(mr_trash_wheel_df), 
                                     colnames(gwynnda_trash_wheel_df))

combined_trash_wheel_df <- mr_trash_wheel_df |> 
  full_join(prof_trash_wheel_df, by = common_cols_between_mr_prof) |> 
  full_join(gwynnda_trash_wheel_df, by = common_cols_between_mr_gwynnda)

unique_trash <- combined_trash_wheel_df |> 
  select(plastic_bottles:sports_balls) 

combined_trash_wheel_clean_df <- combined_trash_wheel_df |> 
  pivot_longer(
    plastic_bottles:sports_balls, 
    names_to = "waste_type", 
    values_to = "number_of_waste_collected"
  )

```
Among the three sheets that we used from the `Mr. Trash Wheel` workbook, the dataset `Mr. Trash Wheel` had the most variables recorded (`r ncol(mr_trash_wheel_df)`), while the datasets `Professor Trash Wheel` and `Gwynnda Trash Wheel` had `r ncol(prof_trash_wheel_df)` and `r ncol(gwynnda_trash_wheel_df)` variables respectively. After combining the three datasets, there are information about `r nrow(combined_trash_wheel_df)` dumpsters, and a total of `r nrow(combined_trash_wheel_clean_df)` observations after tidying the data. For each groups, there are data on volume and weight of trash collected, number and types of each trash collected. There are `r ncol(unique_trash)` types of trash and they are: ``r names(unique_trash)``. We are missing data for ``r unique_cols_between_mr_prof`` in observations from `Professor Trash Wheel`, and ``r unique_cols_between_mr_gwynnda`` from `Gwynnda Trash Wheel`. For the available data, Professor Trash Wheel collected `r total_trash_by_prof` tons trash. Similarly, Gwynnda collected `r total_cigratte_by_gwynnda` cigarette butts in June of 2022. 

## *Problem 3*

Importing datasets from the Great British Bake off:
```{r}
bakeoff_bakers_df <- read.csv("./data/gbb_datasets/bakers.csv") |> 
  janitor::clean_names() |> 
  separate(baker_name, into = c("baker_first_name", "baker_last_name"), sep = " ") |> 
  mutate(baker_first_name = case_when(baker_first_name %in% c("\"Jo\"", "Jo") ~ "Joanne", 
                           TRUE ~ baker_first_name))

bakeoff_bakes_df <- read.csv("./data/gbb_datasets/bakes.csv", na = c("NA", "N/A", "")) |> 
  janitor::clean_names() |> 
  mutate(baker = case_when(baker %in% c("\"Jo\"", "Jo") ~ "Joanne", 
                           TRUE ~ baker))

bakeoff_results_df <- read.csv("./data/gbb_datasets/results.csv", skip = 2, 
                               , na = c("NA", "[a]", "")) |> 
  janitor::clean_names() |> 
  drop_na(c(result)) |> 
  mutate(baker = case_when(baker %in% c("\"Jo\"", "Jo") ~ "Joanne", 
                           TRUE ~ baker)) |> 
  filter((baker == "Diana" & episode < 6) | baker != "Diana")
```

Firstly, for all three datasets, I converted their column names to snake-case, and replaced any other characters (like `N/A`) that represents missing data to `NA`. I identified that Joanne, a contestant from the first season, had been named differently in different datasets. I corroborated this information from the website that Joanna also goes by Jo. I set a consistent name for her. For `bakers.csv`, I separated the `baker_name` column to two columns (``r names(bakeoff_bakers_df)[1:2]``) because the other two datasets only have baker's first name, and the separation is need to be able to link the datasets using the first name and `series`. Similarly, in `results.csv` we see that Diana's result is marked as `WD` in episode five of season five. Diana had to drop out after the fourth episode, so I decided to keep the fifth episode information regarding the departure, and remove the results data for her after that. I also removed data of all episodes post each contestant's knock-out. 

Checking difference between each of the dataset:
```{r}
anti_baker_results_df <- bakeoff_bakers_df |> 
  anti_join(bakeoff_results_df, 
            by = c("baker_first_name" = "baker", 
                   "series" = "series")) 

anti_baker_bakes_df <- bakeoff_bakers_df |> 
  anti_join(bakeoff_bakes_df, 
            by = c("baker_first_name" = "baker", 
                   "series" = "series")) 

anti_bakes_results_df <- bakeoff_results_df |> 
  anti_join(bakeoff_bakes_df, 
            by = c("baker", "series", "episode")) 
```

Joining the datasets and pivot_wider to make it easier to visualize: 
```{r}
joined_baker_bakes_df <- bakeoff_bakers_df |> 
  full_join(bakeoff_bakes_df, 
            by = c("baker_first_name" = "baker", 
                   "series" = "series")) 

joined_baker_results_df <- bakeoff_bakers_df |> 
  full_join(bakeoff_results_df, 
            by = c("baker_first_name" = "baker", 
                   "series" = "series")) 

joined_bakeoff_df <- joined_baker_bakes_df |> 
  full_join(joined_baker_results_df, 
            by = c("baker_first_name", "baker_last_name", 
                   "baker_age", "baker_occupation", "hometown", 
                   "series", "episode")) |> 
  mutate(name = paste(baker_first_name, baker_last_name)) |> 
  select(-c(baker_first_name, baker_last_name)) |> 
  relocate(name, baker_age:hometown) |> 
  arrange(series, episode)

write_csv(joined_bakeoff_df, "./data/gbb_datasets/combined_clean_bakeoff_df.csv")
```

By observing the individual datasets initially and seeing the difference with `anti_join`, we understand that `bakes.csv` only consists of information for bakes between season one and eight. The `results.csv` dataset is missing some results from technical round in season one: for four contestants in episode one and all results for episode six. I first joined `bakers.csv` with the two datasets individually to ensure that all observations have identifiable information such as their last name, occupation, hometown and age, despite the lack of overlap between the `bakes.csv` and `results.csv` for some. Then, I combined the resulting two datasets. I used `full_join` for both the steps to retain all the information necessary. To have a meaningful structure, I combined the first and the last name as a single column, `name`, reordered the dataset to first have the baker's information, series, and episodes, then their bakes and then the results. I also arranged the observations in ascending order for the series and episodes. 

Viewing the winners and star bakes from season 5 through 10:
```{r view_joined_table, fig.width = 10}
joined_bakeoff_df |> 
  mutate(result = to_snake_case(result),
         episode_result = paste(episode, result, sep = "_")) |> 
  filter(series > 4, result %in% c("winner", "star_baker")) |> 
  group_by(name) |> 
  mutate(number_of_stars = n()) |>
  group_by(series) |>
  arrange(desc(number_of_stars)) |> 
  mutate(
    most_stars = case_match(
      number_of_stars,
      max(number_of_stars) ~ name), 
    most_stars = paste(unique(most_stars), collapse = ", "), 
    most_stars = str_replace(most_stars, ", NA", "")) |>
  ungroup() |> 
  arrange(series, episode) |> 
  select(episode_result, name, series, most_stars) |>
  pivot_wider(
    names_from = episode_result,
    values_from = name, 
    names_prefix = "ep_"
  ) |> 
  relocate(series, ep_1_star_baker:ep_10_winner) |> 
  knitr::kable() 
```

In seasons 6 through 9, the winners were as expected since they also had the most stars throughout the season. In season 5 and 10, this was not the case. The most surprising case is for season 10 where the winner, David Atherton, had not gotten a star in any of the prior episodes. Similarly, in season 5, the winner, Nancy Birtwhistle, had only won once before the finale.






